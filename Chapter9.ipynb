{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Implement a deep convolutional neural network from scratch using a popular deep learning framework (e.g., TensorFlow or PyTorch). Train and evaluate the network on a standard image classification dataset, such as CIFAR-10 or MNIST. First, experiment blindly with various hyperparameters and architectures and observe the model’s performance. Second, apply the measurements proposed in this book to reduce the hyperparameter search space and observe the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericfan/miniconda3/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1)\n",
    "test_dataloader = DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.061979740858078\n",
      "Epoch 1, Loss: 0.07952898740768433\n",
      "Epoch 1, Loss: 0.03716222196817398\n",
      "Epoch 1, Loss: 0.022422507405281067\n",
      "Epoch 1, Loss: 0.05648098140954971\n",
      "Epoch 1, Loss: 0.07930899411439896\n",
      "Epoch 2, Loss: 0.017399856820702553\n",
      "Epoch 2, Loss: 0.017844809219241142\n",
      "Epoch 2, Loss: 0.02048613131046295\n",
      "Epoch 2, Loss: 0.09929203242063522\n",
      "Epoch 2, Loss: 0.007487455382943153\n",
      "Epoch 2, Loss: 0.05051618069410324\n",
      "Epoch 3, Loss: 0.0382247120141983\n",
      "Epoch 3, Loss: 0.05837143585085869\n",
      "Epoch 3, Loss: 0.012061964720487595\n",
      "Epoch 3, Loss: 0.028368398547172546\n",
      "Epoch 3, Loss: 0.02847195230424404\n",
      "Epoch 3, Loss: 0.020262017846107483\n",
      "Epoch 4, Loss: 0.03359116241335869\n",
      "Epoch 4, Loss: 0.09503994137048721\n",
      "Epoch 4, Loss: 0.06591596454381943\n",
      "Epoch 4, Loss: 0.011651252396404743\n",
      "Epoch 4, Loss: 0.10653070360422134\n",
      "Epoch 4, Loss: 0.009702167473733425\n",
      "Epoch 5, Loss: 0.015484996140003204\n",
      "Epoch 5, Loss: 0.057421039789915085\n",
      "Epoch 5, Loss: 0.028067696839571\n",
      "Epoch 5, Loss: 0.08785694092512131\n",
      "Epoch 5, Loss: 0.03981878608465195\n",
      "Epoch 5, Loss: 0.0443044938147068\n",
      "Epoch 6, Loss: 0.08924826979637146\n",
      "Epoch 6, Loss: 0.08981427550315857\n",
      "Epoch 6, Loss: 0.005474709905683994\n",
      "Epoch 6, Loss: 0.03363300859928131\n",
      "Epoch 6, Loss: 0.05009596049785614\n",
      "Epoch 6, Loss: 0.22394464910030365\n",
      "Epoch 7, Loss: 0.009524050168693066\n",
      "Epoch 7, Loss: 0.04467159882187843\n",
      "Epoch 7, Loss: 0.015644649043679237\n",
      "Epoch 7, Loss: 0.013650333508849144\n",
      "Epoch 7, Loss: 0.038581423461437225\n",
      "Epoch 7, Loss: 0.023070955649018288\n",
      "Epoch 8, Loss: 0.0016262963181361556\n",
      "Epoch 8, Loss: 0.017267411574721336\n",
      "Epoch 8, Loss: 0.047732844948768616\n",
      "Epoch 8, Loss: 0.0375887006521225\n",
      "Epoch 8, Loss: 0.015568118542432785\n",
      "Epoch 8, Loss: 0.06103388965129852\n",
      "Epoch 9, Loss: 0.0002835577179212123\n",
      "Epoch 9, Loss: 0.027798430994153023\n",
      "Epoch 9, Loss: 0.001205330016091466\n",
      "Epoch 9, Loss: 0.08706586807966232\n",
      "Epoch 9, Loss: 0.10691547393798828\n",
      "Epoch 9, Loss: 0.05826657637953758\n",
      "Epoch 10, Loss: 0.05568136274814606\n",
      "Epoch 10, Loss: 0.04362712800502777\n",
      "Epoch 10, Loss: 0.048068247735500336\n",
      "Epoch 10, Loss: 0.011345572769641876\n",
      "Epoch 10, Loss: 0.044120483100414276\n",
      "Epoch 10, Loss: 0.15880663692951202\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "cnn = NeuralNetwork()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.01)\n",
    "num_epochs = 10\n",
    "\n",
    "def train():\n",
    "    cnn.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            b_x = Variable(images)\n",
    "            b_y = Variable(labels)\n",
    "            \n",
    "            outputs = cnn(b_x)\n",
    "            loss = loss_func(outputs, b_y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            output = cnn(images)\n",
    "            pred = torch.max(output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred == labels).sum().item() / float(labels.size(0))\n",
    "    \n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MEC of this CNN is mostly based on the last linear layer (1568 -> 10), which is roughly 2.5 million bits. However, there are only 60000 instances of 10 classes, which takes only 240000 bits. This shows that the MEC is more than 10 times larger than the input information. Hence, we can shrink the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NewNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NewNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Linear(16 * 7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.08102487772703171\n",
      "Epoch 1, Loss: 0.11710499972105026\n",
      "Epoch 1, Loss: 0.09750881791114807\n",
      "Epoch 1, Loss: 0.06769582629203796\n",
      "Epoch 1, Loss: 0.21913009881973267\n",
      "Epoch 1, Loss: 0.12206210196018219\n",
      "Epoch 2, Loss: 0.07750270515680313\n",
      "Epoch 2, Loss: 0.04412339627742767\n",
      "Epoch 2, Loss: 0.07159687578678131\n",
      "Epoch 2, Loss: 0.035802341997623444\n",
      "Epoch 2, Loss: 0.11703293025493622\n",
      "Epoch 2, Loss: 0.08621673285961151\n",
      "Epoch 3, Loss: 0.11933111399412155\n",
      "Epoch 3, Loss: 0.078800268471241\n",
      "Epoch 3, Loss: 0.048164866864681244\n",
      "Epoch 3, Loss: 0.03147512674331665\n",
      "Epoch 3, Loss: 0.02031896263360977\n",
      "Epoch 3, Loss: 0.03376016020774841\n",
      "Epoch 4, Loss: 0.016535067930817604\n",
      "Epoch 4, Loss: 0.06465445458889008\n",
      "Epoch 4, Loss: 0.026407934725284576\n",
      "Epoch 4, Loss: 0.08631669729948044\n",
      "Epoch 4, Loss: 0.08895490318536758\n",
      "Epoch 4, Loss: 0.03865287825465202\n",
      "Epoch 5, Loss: 0.027885565534234047\n",
      "Epoch 5, Loss: 0.0008036562940105796\n",
      "Epoch 5, Loss: 0.03352247178554535\n",
      "Epoch 5, Loss: 0.04877978935837746\n",
      "Epoch 5, Loss: 0.11759050190448761\n",
      "Epoch 5, Loss: 0.030163424089550972\n",
      "Epoch 6, Loss: 0.01350458525121212\n",
      "Epoch 6, Loss: 0.03404857590794563\n",
      "Epoch 6, Loss: 0.0025022239424288273\n",
      "Epoch 6, Loss: 0.014157092198729515\n",
      "Epoch 6, Loss: 0.08957433700561523\n",
      "Epoch 6, Loss: 0.03620562329888344\n",
      "Epoch 7, Loss: 0.001650196616537869\n",
      "Epoch 7, Loss: 0.07229813933372498\n",
      "Epoch 7, Loss: 0.006624218076467514\n",
      "Epoch 7, Loss: 0.020920677110552788\n",
      "Epoch 7, Loss: 0.004007522948086262\n",
      "Epoch 7, Loss: 0.1073916032910347\n",
      "Epoch 8, Loss: 0.009659107774496078\n",
      "Epoch 8, Loss: 0.028843069449067116\n",
      "Epoch 8, Loss: 0.06278803944587708\n",
      "Epoch 8, Loss: 0.13792917132377625\n",
      "Epoch 8, Loss: 0.07772836834192276\n",
      "Epoch 8, Loss: 0.002569781616330147\n",
      "Epoch 9, Loss: 0.044184934347867966\n",
      "Epoch 9, Loss: 0.03878830000758171\n",
      "Epoch 9, Loss: 0.035225771367549896\n",
      "Epoch 9, Loss: 0.026381276547908783\n",
      "Epoch 9, Loss: 0.025574808940291405\n",
      "Epoch 9, Loss: 0.04313414916396141\n",
      "Epoch 10, Loss: 0.030567731708288193\n",
      "Epoch 10, Loss: 0.08500708639621735\n",
      "Epoch 10, Loss: 0.0368027538061142\n",
      "Epoch 10, Loss: 0.0203747246414423\n",
      "Epoch 10, Loss: 0.0037407942581921816\n",
      "Epoch 10, Loss: 0.12785746157169342\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "cnn = NewNeuralNetwork()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.01)\n",
    "num_epochs = 10\n",
    "\n",
    "def train():\n",
    "    cnn.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            b_x = Variable(images)\n",
    "            b_y = Variable(labels)\n",
    "            \n",
    "            outputs = cnn(b_x)\n",
    "            loss = loss_func(outputs, b_y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test():\n",
    "    cnn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            output = cnn(images)\n",
    "            pred = torch.max(output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred == labels).sum().item() / float(labels.size(0))\n",
    "    \n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I shrank the last linear layer to 784 -> 10, which only has a MEC of 610000 bits, which should still be sufficient for the dataset. As a result, the testing accuracy increased, showing that the prior model is probablly overfitting, and reducing the model size saved both time and gave better performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
